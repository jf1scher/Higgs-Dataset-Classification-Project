{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Final Project for the University Course: AI in Physics\n",
        "\n",
        "Created by: **Jonah Fischer**"
      ],
      "metadata": {
        "id": "tOXzw-0W2380"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook uses the higgs dataset from: https://archive.ics.uci.edu/dataset/280/higgs to distinguish between a signal process which produces Higgs bosons and a background process which does not."
      ],
      "metadata": {
        "id": "0vWYrQrp3G4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/static/public/280/higgs.zip"
      ],
      "metadata": {
        "id": "6u5vxnqV0gzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5704100d-738d-4bcd-bb51-c51313f88464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-10 13:22:01--  https://archive.ics.uci.edu/static/public/280/higgs.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘higgs.zip’\n",
            "\n",
            "higgs.zip               [     <=>            ]   1.60G  58.3MB/s               "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip higgs.zip"
      ],
      "metadata": {
        "id": "K7vIY_8WoBOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "as0swGKN2BwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data\n",
        "df = pd.read_csv('/content/HIGGS.csv.gz', nrows=3000000)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "zy_Tji4M2Dxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change labels\n",
        "df.columns = ['label', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Yweg2r4bsqUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X = df.drop(['label'], axis=1)\n",
        "y = df['label']\n",
        "X.head()"
      ],
      "metadata": {
        "id": "zPP3ekxm2KAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head()"
      ],
      "metadata": {
        "id": "6TAJXZAOr8sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tZJagNfgV803"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature distributions\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "\n",
        "cols = 4\n",
        "fig, axes = plt.subplots(ncols=cols, nrows=7, sharey=False, figsize=(14,14), constrained_layout=True)\n",
        "\n",
        "for i in range(28):\n",
        "    feature = f'f{i}'\n",
        "    col = i % cols\n",
        "    row = i // cols\n",
        "    sns.histplot(df[feature], ax=axes[row][col], kde=True)"
      ],
      "metadata": {
        "id": "fWvMxPgMVOna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cor = df.corr()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.heatmap(cor, annot=True)"
      ],
      "metadata": {
        "id": "_S2neiIYgAvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count signal and background data\n",
        "value_counts = df['label'].value_counts()\n",
        "sns.barplot(x=value_counts.index, y=value_counts.values)\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Count')"
      ],
      "metadata": {
        "id": "wPqa7h9pWhRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature selection\n",
        "#X = X.drop(['f21', 'f22', 'f23', 'f24', 'f25', 'f26'], axis=1)\n",
        "#X.info()"
      ],
      "metadata": {
        "id": "eL8wWsHygwU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn data into tensor\n",
        "X = torch.from_numpy(np.array(X))\n",
        "y = torch.from_numpy(np.array(y))\n",
        "# del df"
      ],
      "metadata": {
        "id": "U0qCGc9OzYti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "eAKWEyo5ufGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "4ud-M8bWvHOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a binary classification model\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, input_features, output_features, hidden_units=8):\n",
        "    '''Initializes classification model.\n",
        "\n",
        "    Args:\n",
        "      input_features (int): Number of input features to the model\n",
        "      output_features (int): Number of output features (number of output classes)\n",
        "      hidden_units (int): Number of hidden units between the layers, default 8\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.linear_layer_stack = nn.Sequential(\n",
        "        nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=hidden_units),\n",
        "        nn.Tanh(),\n",
        "        nn.Linear(in_features=hidden_units, out_features=output_features)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear_layer_stack(x)\n",
        "\n",
        "# Create an instance of the model and send it to the target device\n",
        "model = Classifier(input_features=X.shape[1],\n",
        "                    output_features=1,\n",
        "                    hidden_units=128).to(device)"
      ],
      "metadata": {
        "id": "MZu3hErRvY-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "kCk80sH7wywS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy - out of a 100 examples, what percentage does our model get right?\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item()\n",
        "  acc = (correct/len(y_pred)) * 100\n",
        "  return acc"
      ],
      "metadata": {
        "id": "A-bqrq1c1pHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a loss function\n",
        "loss_fn =  nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Create an optimizer\n",
        "optimizer = torch.optim.Adam(params=model.parameters(),\n",
        "                            lr=0.01)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# Set the number of epoch\n",
        "epochs = 1500\n",
        "\n",
        "# Put the data to target device\n",
        "X_train, y_train = X_train.to(device), y_train.to(device)\n",
        "X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "\n",
        "# Build training and evaluation loop\n",
        "for epoch in range(epochs):\n",
        "  ### Training\n",
        "  model.train()\n",
        "\n",
        "  # 1. Forward pass\n",
        "  y_logits = model(X_train.type(torch.float)).squeeze()\n",
        "  y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred_probs -> pred labels\n",
        "\n",
        "  # 2. Calculate the loss/accuracy\n",
        "  loss = loss_fn(y_logits, # nn.BCEWithLogitsLoss expects raw logits as input\n",
        "                 y_train)\n",
        "  acc = accuracy_fn(y_true=y_train,\n",
        "                    y_pred=y_pred)\n",
        "\n",
        "  # 3. Optimizer zero grad\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  # 4. Loss backward (backpropagation)\n",
        "  loss.backward()\n",
        "\n",
        "  #5. Optimizer step (gradient descent)\n",
        "  optimizer.step()\n",
        "\n",
        "  ### Testing\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    # 1. Forward pass\n",
        "    test_logits = model(X_test.type(torch.float)).squeeze()\n",
        "    test_pred = torch.round(torch.sigmoid(test_logits))\n",
        "\n",
        "    # 2. Calculate test loss/acc\n",
        "    test_loss = loss_fn(test_logits,\n",
        "                        y_test)\n",
        "    test_acc = accuracy_fn(y_true=y_test,\n",
        "                           y_pred=test_pred)\n",
        "\n",
        "  # Print out what's happenin'\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'Epoch: {epoch} | Loss: {loss:.5f}, Acc: {acc:.2f}% | Test loss: {test_loss:.5f}, Test Acc: {test_acc:.2f}%')"
      ],
      "metadata": {
        "id": "yp3b48eAy7uM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's performace\n",
        "from sklearn.metrics import precision_score, confusion_matrix, f1_score\n",
        "\n",
        "y_preds = model(X_test.type(torch.float)).squeeze()\n",
        "y_preds = torch.round(torch.sigmoid(y_preds)).cpu().detach().numpy()\n",
        "\n",
        "precision = precision_score(y_test.cpu().numpy(), y_preds)\n",
        "c_mat = confusion_matrix(y_test.cpu().numpy(), y_preds, normalize='true')\n",
        "F1 = f1_score(y_test.cpu().numpy(), y_preds)\n",
        "\n",
        "print(f'Precision: {precision}')\n",
        "print(f'Confusion Matrix: \\n{c_mat}')\n",
        "print(f'F1-Score: {F1}')"
      ],
      "metadata": {
        "id": "LAoRWbE6zMUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_v1 , X_test_v1, y_train_v1, y_test_v1 = X_train.clone(), X_test.clone(), y_train.clone(), y_test.clone()\n",
        "model_1 = Classifier(input_features=28,\n",
        "                    output_features=1,\n",
        "                    hidden_units=128).to(device)"
      ],
      "metadata": {
        "id": "tZ3WzqbbU09e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.feature_selection import SelectKBest\n",
        "#from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "#f1_score_list = []\n",
        "\n",
        "#for k in range(1, 10):\n",
        "#  selector = SelectKBest(mutual_info_classif, k=k)\n",
        "#  selector.fit(X_train_v1.cpu().numpy(), y_train_v1.cpu().numpy())\n",
        "\n",
        "#  sel_X_train_v1 = selector.transform(X_train_v1)\n",
        "#  sel_X_test_v1 = selector.transform(X_test_v1)\n",
        "\n",
        "#  model_1.fit(sel_X_train_v1, y_train_v1)\n",
        "#  kbest_preds = model_1(sel_X_test_v1)\n",
        "\n",
        "#  f1_score_kbest = round(f1_score(y_test_v1, kbest_preds, average='weighted'), 3)\n",
        "\n",
        "#  f1_score_list.append(f1_score_kbest)"
      ],
      "metadata": {
        "id": "MZS2TELvVAhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fig, ax = plt.subplots()\n",
        "\n",
        "#x = np.arange(1, 29)\n",
        "#y = f1_score_list\n",
        "\n",
        "#sns.barplot(x, y)\n",
        "#ax.set_xlabel('Number of selected features')\n",
        "#ax.set_ylabel('F1-score (weighted)')\n",
        "#ax.set_xticks(x)\n",
        "#ax.set_xtickslabels(x, fontsize=12)\n",
        "\n",
        "#for i, v in enumerate(y):\n",
        "#  plt.text(x=i+1, y=v+0.05, s=str(v), ha='center')\n",
        "\n",
        "#plt.tight_layout()"
      ],
      "metadata": {
        "id": "Z9K01IgeYOUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "scaled_X_train_v1 = scaler.fit_transform(X_train_v1.cpu().numpy())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,9), constrained_layout=True)\n",
        "\n",
        "x = X.columns\n",
        "y = scaled_X_train_v1.var(axis=0)\n",
        "\n",
        "ax.bar(x, y, width=0.2)\n",
        "ax.set_xlabel('Features')\n",
        "ax.set_ylabel('Variance')\n",
        "\n",
        "for i, v in enumerate(y):\n",
        "  plt.text(x=i, y=v+0.002, s=str(round(v, 3)), ha='center')\n",
        "\n",
        "fig.autofmt_xdate()"
      ],
      "metadata": {
        "id": "-iKEaFVjdisT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}